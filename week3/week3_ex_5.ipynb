{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "First, set up the required Python modules and perform some general configuration.\n",
        "\n",
        "(This part of the code follows the [CNN notebook](https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/hf_trainer_cnn.ipynb) that you should already be familiar with.)"
      ],
      "metadata": {
        "id": "wo13ZXoZYB6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the required Python packages using [pip](https://en.wikipedia.org/wiki/Pip):\n",
        "\n",
        "* [`transformers`](https://huggingface.co/docs/transformers/index) is a popular deep learning package\n",
        "* [`datasets`](https://huggingface.co/docs/datasets/) provides support for loading, creating, and manipulating datasets\n",
        "* [`evaluate`](https://huggingface.co/docs/evaluate/index) is a library for easily evaluating machine learning models and datasets\n",
        "* [`accelerate`](https://pypi.org/project/accelerate/) is a wrapper we need to install in order to train torch models using a transformers trainer\n",
        "\n",
        "Both `transformers` and `datasets` are used extensively on this course."
      ],
      "metadata": {
        "id": "qKDDc9isYnxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q transformers datasets evaluate accelerate"
      ],
      "metadata": {
        "id": "4pquj9Xoxaza"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Above, the `!` at the start of the line tells the notebook to run the line as an operating system command rather than Python code, and the `-q` argument to `pip` runs the command in \"quiet\" mode, with less output.)"
      ],
      "metadata": {
        "id": "JyyZCbB0Yxmq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also use the [`pprint`](https://docs.python.org/3/library/pprint.html) (\"pretty-print\") module to format output more readably below. The only difference to just using `print` is that some data structures will be easier to read and interpret."
      ],
      "metadata": {
        "id": "N2oLE1FpY09U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import PrettyPrinter\n",
        "\n",
        "pprint = PrettyPrinter(compact=True).pprint"
      ],
      "metadata": {
        "id": "cQ63zw6BY7tn"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will reduce logging output. The `transformers` library by default produces fairly verbose logging. Commenting out the following code will enable low-priority output (`INFO` logging level and below)."
      ],
      "metadata": {
        "id": "xkrZ6e_FY_2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.disable(logging.INFO)"
      ],
      "metadata": {
        "id": "ZH2bY_GjZG24"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Download and prepare data\n",
        "\n",
        "We will again use the `datasets` library function [`load_dataset`](https://huggingface.co/docs/datasets/master/en/package_reference/loading_methods#datasets.load_dataset) to load a dataset for our experiments."
      ],
      "metadata": {
        "id": "W4x7GbT2ZKUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "\n",
        "\n",
        "dataset = datasets.load_dataset(\"imdb\")"
      ],
      "metadata": {
        "id": "5DKskTuoyCf-"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what the dataset contains:"
      ],
      "metadata": {
        "id": "FVo6_CS2eeIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3K4Fkz7yce7",
        "outputId": "d158c0d6-6025-4fd0-8c2d-4465fad521ce"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    unsupervised: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "and print out an example:"
      ],
      "metadata": {
        "id": "o17ZWi_kf4AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle()\n",
        "del dataset[\"unsupervised\"]\n",
        "pprint(dataset[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd__TIUnf9PD",
        "outputId": "22493834-771f-4dd5-c4a7-fe72edf63d5c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 1,\n",
            " 'text': 'There is no relation at all between Fortier and Profiler but the '\n",
            "         'fact that both are police series about violent crimes. Profiler '\n",
            "         'looks crispy, Fortier looks classic. Profiler plots are quite '\n",
            "         \"simple. Fortier's plot are far more complicated... Fortier looks \"\n",
            "         'more like Prime Suspect, if we have to spot similarities... The main '\n",
            "         'character is weak and weirdo, but have \"clairvoyance\". People like '\n",
            "         'to compare, to judge, to evaluate. How about just enjoying? Funny '\n",
            "         'thing too, people writing Fortier looks American but, on the other '\n",
            "         \"hand, arguing they prefer American series (!!!). Maybe it's the \"\n",
            "         'language, or the spirit, but I think this series is more English '\n",
            "         'than American. By the way, the actors are really good and funny. The '\n",
            "         'acting is not superficial at all...'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Tokenize and vectorize data\n",
        "\n",
        "(This part of the code follows the [CNN notebook](https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/hf_trainer_cnn.ipynb) that you should already be familiar with.)"
      ],
      "metadata": {
        "id": "8KF9UtzUbrBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To tokenize and vectorize the texts of our dataset, we will again use previously created tokenizers through the simple [`AutoTokenizer`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoTokenizer) class.\n",
        "\n",
        "The [`AutoTokenizer.from_pretrained`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoTokenizer.from_pretrained) function can load the tokenizer associated with any of the large number of models found in the [Hugging Face models repository](https://huggingface.co/models). Here, our texts are in English, and we'll load the tokenizer for the [`bert-base-cased`](https://huggingface.co/bert-base-cased) model.\n",
        "\n",
        "(**Note**: we're not actually using the BERT model here, just its tokenizer.)"
      ],
      "metadata": {
        "id": "H9RBff6Rkfyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "wjrAGcFtymJF",
        "outputId": "22670b2a-21fb-4f6d-d486-ae69b7e299bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in the [CNN notebook](https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/hf_trainer_cnn.ipynb), we will define a simple tokenization function and tokenize and vectorize our whole dataset with the tokenizer by calling the [`Dataset.map`](https://huggingface.co/docs/datasets/v2.14.4/en/package_reference/main_classes#datasets.Dataset.map) function.\n",
        "\n",
        "Note that here we're providing a `max_length` argument and `truncation=True` in the tokenizer call. This limits the maximum length of outputs to the given length (see the [tokenizers documentation](https://huggingface.co/docs/transformers/preprocessing#everything-you-always-wanted-to-know-about-padding-and-truncation) for details). This makes training faster, potentially at some cost in performance."
      ],
      "metadata": {
        "id": "mjEeyPsXc12X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple function that applies the tokenizer\n",
        "def tokenize(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        max_length=128,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "# Apply the tokenizer to the whole dataset using .map()\n",
        "dataset = dataset.map(tokenize)"
      ],
      "metadata": {
        "id": "K2c4lFKTywlu",
        "outputId": "bc51a227-4d56-4dd6-f66c-94d2c35e99e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157,
          "referenced_widgets": [
            "1bde44f98d21405989366485c4855484",
            "5042b7b832924eaa893e737e4a8e86d4",
            "b0f9f13a8aff44e2893301b38dff5104",
            "869d8370453945a3bbc5bed0d1c1d825",
            "4fb60e70144b44ab84afd778cbd18134",
            "a18421520934491398e076c7b8659d2c",
            "9847af1b021d4ff0b86bd64af491e06b",
            "16d8a9b7d06c4a9d8e51452a12c1b297",
            "ec665b918f3147259cd6b5dca858ef26",
            "3c8e2122539142c797fa012a07c725d3",
            "cc4933f22ffa435daf0bd65d7d2517c0",
            "c5f1ef246688480e8256d69dcd9137b9",
            "6147fba49a8b4de0a0f5974f388317a6",
            "197ccbd735bb4739ad85b73585545d2d",
            "d7f427a8fb19461b9a1b9b5fee480a50",
            "88e0188d1c1041c6a13cc66782a60b86",
            "aea14fe276cc455fba129990f28fcc7f",
            "405995b5d9f74c17a1afbdc9570ae6a4",
            "5254127ba81044f998b872b85dc97259",
            "7e94089a08cd46a890e952581380c182",
            "b2eff6ec63a7487186a5d23e7f754d06",
            "258aed215a9f408d8caabb4c466b052d"
          ]
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bde44f98d21405989366485c4855484"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5f1ef246688480e8256d69dcd9137b9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Build model\n",
        "\n",
        "As usual, we will create a PyTorch model class with an `__init__()` function that creates the layers and a `forward()` function which implements the actual computation. For more information on these, please see the [PyTorch tutorial](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html)."
      ],
      "metadata": {
        "id": "AiX7WeW2X5gv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're here building a simple RNN with the following structure:\n",
        "\n",
        "* As in the [CNN](https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/hf_trainer_cnn.ipynb), the token IDs are first mapped to embeddings of a user-specified size (`config.embedding_dim`) in a [torch.nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) layer. Note that here the embeddings are initialized randomly and learned along with other model weights. In real-world applications, the embeddings would typically be initialized with previously learned weights.\n",
        "* Second, the embedded inputs are passed through an RNN ([torch.nn.RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)), which produces a series of outputs ($(y_1, \\ldots, y_n)$, where $n$ is the length of the input) and the final hidden state $h_n$. Here, we will only use the last output $y_n$.\n",
        "* Finally, there is a fully connected layer ([torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)) that maps the last RNN output to the two possible output values of the classifier.\n",
        "\n",
        "We can interpret this model as processing the input step by step, attempting to identify tokens (embeddings) that in the context of its previous input express either positive or negative opinions, and to output a value at the end of the sequence that can be mapped to the positive or negative class."
      ],
      "metadata": {
        "id": "8UQlKM1Vfrha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the `forward` function we mostly just pass the input through the layers, with the following additional steps:\n",
        "\n",
        "* To invoke the RNN, we need to provide the value of the initial hidden state $h_0$. Here we simply use [torch.zeros](https://pytorch.org/docs/stable/generated/torch.zeros.html) to create a tensor of the appropriate size filled with zeros.\n",
        "* To get the value of the last item in the sequence of RNN outputs (`rnn_outputs`), we slice the three-dimensional tensor (batch, rnn step, output dim) with `rnn_outputs[:, -1, :]`. This returns all values in the first and last dimensions, and the last in the second. If you are not familar with this syntax, consider the following example:"
      ],
      "metadata": {
        "id": "mZqIlxnDOxbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "a = numpy.array([\n",
        "  [[11], [12], [13]],\n",
        "  [[21], [22], [23]],\n",
        "  [[31], [32], [33]],\n",
        "])\n",
        "\n",
        "print(a[:, -1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPWGCx8ODwS9",
        "outputId": "28ac622b-5c6c-40fc-9095-b465e69dd4da"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13]\n",
            " [23]\n",
            " [33]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(The two points above can be considered technical details and understanding them in detail is not required to understand the model.)"
      ],
      "metadata": {
        "id": "JlGCWXiSEvH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's the model:"
      ],
      "metadata": {
        "id": "UCgAqPAeEypM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "# This gives a new name to the config class, just for convenience\n",
        "BasicConfig = transformers.PretrainedConfig\n",
        "\n",
        "\n",
        "# This is the model\n",
        "class SimpleRNN(transformers.PreTrainedModel):\n",
        "\n",
        "    config_class = BasicConfig\n",
        "\n",
        "    # In the initialization method, one instantiates the layers\n",
        "    # these will be the parameters of the model\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        # Embedding layer: vocab size x embedding dim\n",
        "        self.embeddings = torch.nn.Embedding(\n",
        "            num_embeddings=config.vocab_size,\n",
        "            embedding_dim=config.embedding_dim\n",
        "        )\n",
        "        # RNN with configurable hidden size and nonlinearity\n",
        "        self.rnn = torch.nn.LSTM(\n",
        "            input_size=config.embedding_dim,\n",
        "            hidden_size=config.hidden_size,\n",
        "            num_layers=config.num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True # added for bidirectionality\n",
        "        )\n",
        "        # Output layer: embedding size to output size\n",
        "        self.output_layer = torch.nn.Linear(\n",
        "            in_features=config.hidden_size*2,\n",
        "            out_features=config.num_labels\n",
        "        )\n",
        "        # Loss function: standard loss for classification\n",
        "        self.loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    N = batch size\n",
        "    L = seq length\n",
        "    D = 2 if bidirectional=True, otherwise 1\n",
        "    H_in = input_size\n",
        "    H_cell = hidden size\n",
        "    H_out = proj_size if proj_size > 0 otherwise hidden_size\n",
        "    \"\"\"\n",
        "    def forward(self, input_ids, labels=None, attention_mask=None):\n",
        "        # Embed input ids\n",
        "        x = self.embeddings(input_ids)\n",
        "        # Set initial hidden state to all-zero values\n",
        "        batch_size = x.shape[0]\n",
        "        \"\"\"\n",
        "        h_0: tensor of shape (Dâˆ—num_layers,Hout)(Dâˆ—num_layers,Houtâ€‹) for unbatched input or (Dâˆ—num_layers,N,Hout)(Dâˆ—num_layers,N,Houtâ€‹)\n",
        "        containing the initial hidden state for each element in the input sequence.\n",
        "        Defaults to zeros if (h_0, c_0) is not provided.\n",
        "        \"\"\"\n",
        "        h0 = torch.zeros(\n",
        "            (self.config.num_layers*2, batch_size, self.config.hidden_size),\n",
        "            device=input_ids.device    # place on same device as input\n",
        "        )\n",
        "        \"\"\"\n",
        "        c_0: tensor of shape (Dâˆ—num_layers,Hcell)(Dâˆ—num_layers,Hcellâ€‹)\n",
        "        for unbatched input or (Dâˆ—num_layers,N,Hcell)(Dâˆ—num_layers,N,Hcellâ€‹)\n",
        "        containing the initial cell state for each element in the input sequence.\n",
        "        Defaults to zeros if (h_0, c_0) is not provided.\n",
        "        \"\"\"\n",
        "        c0 = torch.zeros(\n",
        "            (self.config.num_layers*2, batch_size, self.config.hidden_size),\n",
        "            device=input_ids.device\n",
        "        )\n",
        "        # Run RNN repeatedly to get sequence of outputs and last hidden state\n",
        "        rnn_outputs, (h_n, c_n) = self.rnn(x, (h0,c0))\n",
        "        # Get last RNN output\n",
        "        y_n = rnn_outputs[:, -1, :]\n",
        "        # Map to outputs with fully connected layer\n",
        "        output = self.output_layer(y_n)\n",
        "\n",
        "        # Return value computed as in MLP and CNN:\n",
        "        if labels is not None:\n",
        "            # We have labels, so we can calculate the loss\n",
        "            return (self.loss(output,labels), output)\n",
        "        else:\n",
        "            # No labels, so just return the output\n",
        "            return (output,)"
      ],
      "metadata": {
        "id": "9kyQQhu0_wep"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Configure and train model"
      ],
      "metadata": {
        "id": "Tmj91CdCT-fJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll first configure and instantiate the model. Here `vocab_size` should always be the vocabulary size of the tokenizer and `num_labels` the number of unique labels in the data (as here), but the others are hyperparameters that you can choose:\n",
        "\n",
        "* `embedding_dim`: the size of the word (i.e. token) embeddings\n",
        "* `hidden_size`: the size of the RNN hidden state vector _h_\n",
        "* `num_layers`: number of stacked RNN layers\n",
        "* `nonlinearity`: the non-linear function to apply in RNN (`'tanh'` or `'relu'`)"
      ],
      "metadata": {
        "id": "pVTopuNPW26S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "num_layers â€“ Number of recurrent layers.\n",
        "E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM,\n",
        "with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1\n",
        "  \"\"\"\n",
        "\n",
        "config = BasicConfig(\n",
        "    vocab_size = tokenizer.vocab_size,\n",
        "    num_labels = len(set(dataset[\"train\"][\"label\"])),\n",
        "    embedding_dim = 64,\n",
        "    hidden_size = 96,\n",
        "\n",
        "    num_layers = 2, # changed from 1 to 2\n",
        "    #nonlinearity = \"tanh\", not needed as LSTM doesnt approve this as parameter\n",
        ")\n",
        "\n",
        "model = SimpleRNN(config)"
      ],
      "metadata": {
        "id": "nd_usta7WzTX"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training arguments are set similarly as in the [CNN notebook](https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/hf_trainer_cnn.ipynb). Many number of these settings relate to the frequency of evaluation and output during training, but the following are hyperparameters that you may wish to adjust:\n",
        "\n",
        "* `learning_rate`: the step size for weight updates\n",
        "* `per_device_train_batch_size`: number of examples per batch\n",
        "* `max_steps`: the maximum number of steps to train for"
      ],
      "metadata": {
        "id": "q5xkBXWDUL-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training arguments\n",
        "trainer_args = transformers.TrainingArguments(\n",
        "    \"checkpoints\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    logging_strategy=\"steps\",\n",
        "    load_best_model_at_end=True,\n",
        "    eval_steps=500,\n",
        "    logging_steps=500,\n",
        "    learning_rate=0.001,\n",
        "    per_device_train_batch_size=8,\n",
        "    max_steps=2500,\n",
        ")"
      ],
      "metadata": {
        "id": "gVW-yGhYItWk",
        "outputId": "7760cc27-510b-4ae0-92d6-3d38fee1758d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll then define the standard accuracy metric (ratio of correct out of all predictions), create a [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorWithPadding) to pad inputs to the same length (as required for batching) and an [EarlyStoppingCallback](https://huggingface.co/docs/transformers/main_classes/callback#transformers.EarlyStoppingCallback) to stop training when performance fails to improve for the given number of evaluations.\n",
        "\n",
        "(These should all be familiar to you from the [CNN notebook](https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/hf_trainer_cnn.ipynb))"
      ],
      "metadata": {
        "id": "lRE6YtHvUTcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "\n",
        "def compute_accuracy(outputs_and_labels):\n",
        "    outputs, labels = outputs_and_labels\n",
        "    predictions = outputs.argmax(axis=-1) #pick the index of the \"winning\" label\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "data_collator = transformers.DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "# Argument gives the number of steps of patience before early stopping\n",
        "early_stopping = transformers.EarlyStoppingCallback(\n",
        "    early_stopping_patience=5\n",
        ")"
      ],
      "metadata": {
        "id": "miilVFfCIhR1"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, as in the [CNN notebook](https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/hf_trainer_cnn.ipynb), we'll create a simple custom [callback](https://huggingface.co/docs/transformers/main_classes/callback) to store values logged during training so that we can more easily examine them later. (This is only needed for visualization and is not necessary to understand in detail.)"
      ],
      "metadata": {
        "id": "pd3o8RIdaWqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "class LogSavingCallback(transformers.TrainerCallback):\n",
        "    def on_train_begin(self, *args, **kwargs):\n",
        "        self.logs = defaultdict(list)\n",
        "        self.training = True\n",
        "\n",
        "    def on_train_end(self, *args, **kwargs):\n",
        "        self.training = False\n",
        "\n",
        "    def on_log(self, args, state, control, logs, model=None, **kwargs):\n",
        "        if self.training:\n",
        "            for k, v in logs.items():\n",
        "                if k != \"epoch\" or v not in self.logs[k]:\n",
        "                    self.logs[k].append(v)\n",
        "\n",
        "training_logs = LogSavingCallback()"
      ],
      "metadata": {
        "id": "0EFQebkDYXES"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then pass the model, trainer arguments, training and evaluation data, metric, the collator, and the callbacks to a [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) and call `.train()` to train the model."
      ],
      "metadata": {
        "id": "GCuvqB0bVPI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    args=trainer_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    compute_metrics=compute_accuracy,\n",
        "    data_collator=data_collator,\n",
        "    callbacks=[early_stopping, training_logs]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "4lKiSRNJVOvJ",
        "outputId": "cf1bf09d-85b4-4211-d7b8-68244a5b9f1f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:26, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.690300</td>\n",
              "      <td>0.691788</td>\n",
              "      <td>0.523720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.687600</td>\n",
              "      <td>0.686373</td>\n",
              "      <td>0.547680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.683700</td>\n",
              "      <td>0.681575</td>\n",
              "      <td>0.569080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.673200</td>\n",
              "      <td>0.661619</td>\n",
              "      <td>0.611600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.651865</td>\n",
              "      <td>0.629200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2500, training_loss=0.6769697509765625, metrics={'train_runtime': 86.0568, 'train_samples_per_second': 232.405, 'train_steps_per_second': 29.051, 'total_flos': 5337937920000.0, 'train_loss': 0.6769697509765625, 'epoch': 0.8})"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Results"
      ],
      "metadata": {
        "id": "VId9dMvAO6aA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate and print out results:"
      ],
      "metadata": {
        "id": "h0VrtFCrO-LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate(dataset[\"test\"])\n",
        "\n",
        "pprint(eval_results)\n",
        "\n",
        "print('Accuracy:', eval_results['eval_accuracy'])"
      ],
      "metadata": {
        "id": "7zw3iJ7tPS7V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "e22a87f5-0bde-4138-a11a-ff34cd414014"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 0.8,\n",
            " 'eval_accuracy': 0.6292,\n",
            " 'eval_loss': 0.6518653631210327,\n",
            " 'eval_runtime': 13.8098,\n",
            " 'eval_samples_per_second': 1810.311,\n",
            " 'eval_steps_per_second': 226.289}\n",
            "Accuracy: 0.6292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also have a look at training and evaluation loss and evaluation accuracy progression as we did in the [CNN notebook](https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/hf_trainer_cnn.ipynb). (The code here is only for visualization and you do not need to understand it, but you should aim to be able to interpret the plots.)"
      ],
      "metadata": {
        "id": "xm1ZAFTObyf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CHANGES MADE AND RESULTS"
      ],
      "metadata": {
        "id": "EvbB3IzAFwLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) Start from last week's RNN notebook, and update it to use an LSTM cell instead of the vanilla RNN cell. You can begin by simply replacing torch.nn.RNN with torch.nn.LSTM. However, expect a few errors. Try to debug the code by examining the error messages and referring to the RNN and LSTM cell documentation.**bold text**"
      ],
      "metadata": {
        "id": "BKdnq7YYF7MF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changed self.rnn to self.LSTM\n",
        "\n",
        "```python\n",
        "self.rnn = torch.nn.LSTM(\n",
        "```\n",
        "\n",
        "removed nonliniarity parameter from the config\n",
        "\n",
        "```python\n",
        "self.rnn = torch.nn.LSTM(\n",
        "            input_size=config.embedding_dim,\n",
        "            hidden_size=config.hidden_size,\n",
        "            num_layers=config.num_layers,\n",
        "            nonlinearity=config.nonlinearity, # removed this\n",
        "            batch_first=True\n",
        "       )\n",
        "```\n",
        "                          \n",
        "Modified the `def forward`\n",
        "\n",
        "```python\n",
        "c0 = torch.zeros(\n",
        "    (self.config.num_layers, batch_size, self.config.hidden_size),\n",
        "    device=input_ids.device\n",
        ")\n",
        "# Run RNN repeatedly to get sequence of outputs and last hidden state\n",
        "rnn_outputs, (h_n, c_n) = self.rnn(x, (h0,c0))\n",
        "```\n",
        "c0, c_n new parameters and self.rnn call to contain initialized c0\n",
        "\n",
        "#### RESULTS OF CHANGES\n",
        "\n",
        "```python3\n",
        "{'epoch': 0.8,\n",
        " 'eval_accuracy': 0.57432,\n",
        " 'eval_loss': 0.6802768707275391,\n",
        " 'eval_runtime': 17.2538,\n",
        " 'eval_samples_per_second': 1448.958,\n",
        " 'eval_steps_per_second': 181.12}\n",
        "Accuracy: 0.57432\n",
        "```"
      ],
      "metadata": {
        "id": "XoDMLucqGLmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) After successfully training with the LSTM cell, attempt to enhance performance by implementing bidirectional and stacked architectures. Once again, few errors are to be expected.\n",
        "\n",
        "Changed num_layers 1 ==> 2\n",
        "\n",
        "```python\n",
        "\n",
        "\"\"\"\n",
        "num_layers â€“ Number of recurrent layers.\n",
        "E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM,\n",
        "with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1\n",
        "  \"\"\"\n",
        "\n",
        "config = BasicConfig(\n",
        "    vocab_size = tokenizer.vocab_size,\n",
        "    num_labels = len(set(dataset[\"train\"][\"label\"])),\n",
        "    embedding_dim = 64,\n",
        "    hidden_size = 96,\n",
        "\n",
        "    num_layers = 2, # changed from 1 to 2\n",
        "    #nonlinearity = \"tanh\", not needed as LSTM doesnt approve this as parameter\n",
        ")\n",
        "\n",
        "model = SimpleRNN(config)\n",
        "\n",
        "```\n",
        "RESULTS OF CHANGES\n",
        "\n",
        "```python3\n",
        "{'epoch': 0.8,\n",
        " 'eval_accuracy': 0.51548,\n",
        " 'eval_loss': 0.6923003792762756,\n",
        " 'eval_runtime': 11.5596,\n",
        " 'eval_samples_per_second': 2162.695,\n",
        " 'eval_steps_per_second': 270.337}\n",
        "Accuracy: 0.51548\n",
        "```\n",
        "\n",
        "Changed LSTM to bidirectional with changes in:\n",
        "\n",
        "`def __init__`\n",
        "\n",
        "increased `D` value (hidden as 1 in the original lstm) to 2 in `config.hidden_size`\n",
        "\n",
        "```python\n",
        "\n",
        "# Output layer: embedding size to output size\n",
        "self.output_layer = torch.nn.Linear(\n",
        "  in_features=config.hidden_size*2,\n",
        "  out_features=config.num_labels\n",
        ")\n",
        "```\n",
        "\n",
        "`def forward`\n",
        "\n",
        "increased `D` value (hidden as 1 in the original lstm) to 2 in h0 and c0\n",
        "\n",
        "```python\n",
        "\"\"\"\n",
        "h_0: tensor of shape (Dâˆ—num_layers,Hout)(Dâˆ—num_layers,Houtâ€‹) for unbatched input or (Dâˆ—num_layers,N,Hout)(Dâˆ—num_layers,N,Houtâ€‹)\n",
        "containing the initial hidden state for each element in the input sequence.\n",
        "Defaults to zeros if (h_0, c_0) is not provided.\n",
        "\"\"\"\n",
        "h0 = torch.zeros(\n",
        "    (self.config.num_layers*2, batch_size, self.config.hidden_size),\n",
        "    device=input_ids.device    # place on same device as input\n",
        ")\n",
        "\"\"\"\n",
        "c_0: tensor of shape (Dâˆ—num_layers,Hcell)(Dâˆ—num_layers,Hcellâ€‹)\n",
        "for unbatched input or (Dâˆ—num_layers,N,Hcell)(Dâˆ—num_layers,N,Hcellâ€‹)\n",
        "containing the initial cell state for each element in the input sequence.\n",
        "Defaults to zeros if (h_0, c_0) is not provided.\n",
        "\"\"\"\n",
        "c0 = torch.zeros(\n",
        "    (self.config.num_layers*2, batch_size, self.config.hidden_size),\n",
        "    device=input_ids.device\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```python3\n",
        "{'epoch': 0.8,\n",
        " 'eval_accuracy': 0.6292,\n",
        " 'eval_loss': 0.6518653631210327,\n",
        " 'eval_runtime': 13.8098,\n",
        " 'eval_samples_per_second': 1810.311,\n",
        " 'eval_steps_per_second': 226.289}\n",
        "Accuracy: 0.6292\n",
        "```\n"
      ],
      "metadata": {
        "id": "K3PKhTO-HTzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPTUNA STUDY FOR LEARNING RATE AND NUMBER OF LAYERS FOR BIDIRECTINAL LSTM"
      ],
      "metadata": {
        "id": "tS-7v8weJd7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna"
      ],
      "metadata": {
        "id": "ICNWKJlbOS2d"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the search space for hyperparameters\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 5e-4, 5e-2, log=True)\n",
        "    num_layers = trial.suggest_int(\"num_layers\",1,5)\n",
        "\n",
        "    config = BasicConfig(\n",
        "      vocab_size = tokenizer.vocab_size,\n",
        "      num_labels = len(set(dataset[\"train\"][\"label\"])),\n",
        "      embedding_dim = 64,\n",
        "      hidden_size = 96,\n",
        "      num_layers = num_layers\n",
        "    )\n",
        "\n",
        "    model = SimpleRNN(config)\n",
        "\n",
        "    # Set training arguments\n",
        "    trainer_args = transformers.TrainingArguments(\n",
        "        \"checkpoints\",\n",
        "        evaluation_strategy=\"steps\",\n",
        "        logging_strategy=\"steps\",\n",
        "        load_best_model_at_end=True,\n",
        "        eval_steps=500,\n",
        "        logging_steps=500,\n",
        "        learning_rate=learning_rate, # <--- parameter goes here\n",
        "        per_device_train_batch_size=8,\n",
        "        max_steps=2500,\n",
        "    )\n",
        "\n",
        "    trainer = transformers.Trainer(\n",
        "        model=model,\n",
        "        args=trainer_args,\n",
        "        train_dataset=dataset[\"train\"],\n",
        "        eval_dataset=dataset[\"test\"],\n",
        "        compute_metrics=compute_accuracy,\n",
        "        data_collator=data_collator,\n",
        "        callbacks=[transformers.EarlyStoppingCallback(early_stopping_patience=5), LogSavingCallback()]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate(dataset[\"test\"])\n",
        "    print('Learning rate:', learning_rate, 'Number of layers:', num_layers, 'Accuracy:', eval_results['eval_accuracy'])\n",
        "    return eval_results['eval_accuracy']\n",
        "\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=7) # <--- How many trials we run, more would be needed in real case!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kPayKr-IJdgK",
        "outputId": "e8447053-fda2-4d2b-cfbb-27a87c8ace83"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:14, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.690400</td>\n",
              "      <td>0.698311</td>\n",
              "      <td>0.500680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.689700</td>\n",
              "      <td>0.688449</td>\n",
              "      <td>0.535400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.679100</td>\n",
              "      <td>0.672322</td>\n",
              "      <td>0.606040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.653900</td>\n",
              "      <td>0.648847</td>\n",
              "      <td>0.637440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.628700</td>\n",
              "      <td>0.627360</td>\n",
              "      <td>0.667280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.001785342739404788 Number of layers: 1 Accuracy: 0.66728\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:24, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.695600</td>\n",
              "      <td>0.692671</td>\n",
              "      <td>0.510360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.693600</td>\n",
              "      <td>0.694798</td>\n",
              "      <td>0.510360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.693700</td>\n",
              "      <td>0.692901</td>\n",
              "      <td>0.510360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.693100</td>\n",
              "      <td>0.692592</td>\n",
              "      <td>0.510360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.692900</td>\n",
              "      <td>0.692889</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.012573706789392404 Number of layers: 2 Accuracy: 0.51036\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:29, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.692698</td>\n",
              "      <td>0.510280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.693300</td>\n",
              "      <td>0.694344</td>\n",
              "      <td>0.500160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.693400</td>\n",
              "      <td>0.692916</td>\n",
              "      <td>0.510360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.693100</td>\n",
              "      <td>0.692652</td>\n",
              "      <td>0.510360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.692800</td>\n",
              "      <td>0.692886</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.008192600104922971 Number of layers: 3 Accuracy: 0.51036\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:13, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.692000</td>\n",
              "      <td>0.691874</td>\n",
              "      <td>0.525800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.694700</td>\n",
              "      <td>0.695432</td>\n",
              "      <td>0.510760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.693800</td>\n",
              "      <td>0.691803</td>\n",
              "      <td>0.521400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.686800</td>\n",
              "      <td>0.679185</td>\n",
              "      <td>0.575640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.673800</td>\n",
              "      <td>0.673603</td>\n",
              "      <td>0.590360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.0007987956655643505 Number of layers: 1 Accuracy: 0.59036\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:30, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.691000</td>\n",
              "      <td>0.691095</td>\n",
              "      <td>0.534320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.686300</td>\n",
              "      <td>0.676524</td>\n",
              "      <td>0.583880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.684300</td>\n",
              "      <td>0.680849</td>\n",
              "      <td>0.570520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.670500</td>\n",
              "      <td>0.658928</td>\n",
              "      <td>0.624960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.648800</td>\n",
              "      <td>0.656658</td>\n",
              "      <td>0.624400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.0005474328674891419 Number of layers: 3 Accuracy: 0.6244\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:30, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.692600</td>\n",
              "      <td>0.693651</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.693100</td>\n",
              "      <td>0.693926</td>\n",
              "      <td>0.499920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.693400</td>\n",
              "      <td>0.693293</td>\n",
              "      <td>0.499960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.693300</td>\n",
              "      <td>0.693160</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.693200</td>\n",
              "      <td>0.693235</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.0021293420185889444 Number of layers: 3 Accuracy: 0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:30, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.691200</td>\n",
              "      <td>0.700542</td>\n",
              "      <td>0.500080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.690800</td>\n",
              "      <td>0.691456</td>\n",
              "      <td>0.513480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.690600</td>\n",
              "      <td>0.689649</td>\n",
              "      <td>0.538240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.688900</td>\n",
              "      <td>0.685262</td>\n",
              "      <td>0.556760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.683000</td>\n",
              "      <td>0.686448</td>\n",
              "      <td>0.536920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.0010050086030851926 Number of layers: 3 Accuracy: 0.55676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning rate: 0.001785342739404788 Number of layers: 1 Accuracy: 0.66728\n"
      ],
      "metadata": {
        "id": "z3E7Kw8QWq5a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "APWgCghPWsjv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wo13ZXoZYB6J",
        "W4x7GbT2ZKUJ",
        "8KF9UtzUbrBA"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1bde44f98d21405989366485c4855484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5042b7b832924eaa893e737e4a8e86d4",
              "IPY_MODEL_b0f9f13a8aff44e2893301b38dff5104",
              "IPY_MODEL_869d8370453945a3bbc5bed0d1c1d825"
            ],
            "layout": "IPY_MODEL_4fb60e70144b44ab84afd778cbd18134"
          }
        },
        "5042b7b832924eaa893e737e4a8e86d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a18421520934491398e076c7b8659d2c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9847af1b021d4ff0b86bd64af491e06b",
            "value": "Map:â€‡100%"
          }
        },
        "b0f9f13a8aff44e2893301b38dff5104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16d8a9b7d06c4a9d8e51452a12c1b297",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec665b918f3147259cd6b5dca858ef26",
            "value": 25000
          }
        },
        "869d8370453945a3bbc5bed0d1c1d825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c8e2122539142c797fa012a07c725d3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cc4933f22ffa435daf0bd65d7d2517c0",
            "value": "â€‡25000/25000â€‡[00:30&lt;00:00,â€‡915.23â€‡examples/s]"
          }
        },
        "4fb60e70144b44ab84afd778cbd18134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a18421520934491398e076c7b8659d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9847af1b021d4ff0b86bd64af491e06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16d8a9b7d06c4a9d8e51452a12c1b297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec665b918f3147259cd6b5dca858ef26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c8e2122539142c797fa012a07c725d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4933f22ffa435daf0bd65d7d2517c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5f1ef246688480e8256d69dcd9137b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6147fba49a8b4de0a0f5974f388317a6",
              "IPY_MODEL_197ccbd735bb4739ad85b73585545d2d",
              "IPY_MODEL_d7f427a8fb19461b9a1b9b5fee480a50"
            ],
            "layout": "IPY_MODEL_88e0188d1c1041c6a13cc66782a60b86"
          }
        },
        "6147fba49a8b4de0a0f5974f388317a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea14fe276cc455fba129990f28fcc7f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_405995b5d9f74c17a1afbdc9570ae6a4",
            "value": "Map:â€‡100%"
          }
        },
        "197ccbd735bb4739ad85b73585545d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5254127ba81044f998b872b85dc97259",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e94089a08cd46a890e952581380c182",
            "value": 25000
          }
        },
        "d7f427a8fb19461b9a1b9b5fee480a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2eff6ec63a7487186a5d23e7f754d06",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_258aed215a9f408d8caabb4c466b052d",
            "value": "â€‡25000/25000â€‡[00:30&lt;00:00,â€‡801.80â€‡examples/s]"
          }
        },
        "88e0188d1c1041c6a13cc66782a60b86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aea14fe276cc455fba129990f28fcc7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "405995b5d9f74c17a1afbdc9570ae6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5254127ba81044f998b872b85dc97259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e94089a08cd46a890e952581380c182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2eff6ec63a7487186a5d23e7f754d06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258aed215a9f408d8caabb4c466b052d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}